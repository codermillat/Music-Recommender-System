{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codermillat/Music-Recommender-System/blob/main/music_recommender_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC3P4CAAJgRA"
      },
      "source": [
        "# Music Recommender System\n",
        "A comprehensive music recommendation system using collaborative filtering, content-based, and popularity-based approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TKK67OG8JgRB",
        "outputId": "d18c669a-16e9-48c7-9a7d-3c2e98921741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -q numpy pandas scikit-learn scikit-surprise matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J432I6VoJgRC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from surprise import Dataset, Reader, KNNWithMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Set Seaborn style directly\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Optional: If you want to use Matplotlib's built-in styles inspired by Seaborn\n",
        "# plt.style.use('seaborn-whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "metadata": {
        "id": "8diAH13rJwnL",
        "outputId": "0b2aaf0d-40db-4860-afcf-48aa3d473697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXiDTbmeJgRC"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "triplets = pd.read_csv('data/kaggle_visible_evaluation_triplets.txt',\n",
        "                      sep='\\t', names=['user_id', 'song_id', 'freq'])\n",
        "\n",
        "tracks = pd.read_csv('data/unique_tracks.txt',\n",
        "                     sep='<SEP>', names=['track_id', 'song_id', 'artist_name', 'release'])\n",
        "\n",
        "# Merge data\n",
        "df = pd.merge(triplets, tracks[['song_id', 'artist_name', 'release']],\n",
        "              on='song_id', how='left')\n",
        "\n",
        "print(\"Dataset Statistics:\")\n",
        "print(f\"Total Users: {df['user_id'].nunique():,}\")\n",
        "print(f\"Total Songs: {df['song_id'].nunique():,}\")\n",
        "print(f\"Total Artists: {df['artist_name'].nunique():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us4g2qYTJgRC"
      },
      "source": [
        "## 1. Popularity-Based Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbqifvGjJgRD"
      },
      "outputs": [],
      "source": [
        "def get_popular_songs(df, n=10):\n",
        "    return df.groupby(['song_id', 'artist_name', 'release'])['freq'].sum()\\\n",
        "             .sort_values(ascending=False).head(n).reset_index()\n",
        "\n",
        "popular_songs = get_popular_songs(df)\n",
        "print(\"\\nTop 10 Most Popular Songs:\")\n",
        "display(popular_songs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQDyjCNsJgRD"
      },
      "source": [
        "## 2. Collaborative Filtering Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ14RkCdJgRD"
      },
      "outputs": [],
      "source": [
        "def get_collaborative_recommendations(df, user_id, n=5):\n",
        "    reader = Reader()\n",
        "    data = Dataset.load_from_df(df[['user_id', 'song_id', 'freq']], reader)\n",
        "\n",
        "    algo = KNNWithMeans(k=50, sim_options={'name': 'cosine', 'user_based': True})\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo.fit(trainset)\n",
        "\n",
        "    # Get songs the user hasn't listened to\n",
        "    user_songs = set(df[df['user_id'] == user_id]['song_id'])\n",
        "    songs_to_predict = list(set(df['song_id']) - user_songs)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = [algo.predict(user_id, song_id) for song_id in songs_to_predict[:100]]\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    results = []\n",
        "    for pred in predictions[:n]:\n",
        "        song_info = df[df['song_id'] == pred.iid].iloc[0]\n",
        "        results.append({\n",
        "            'Artist': song_info['artist_name'],\n",
        "            'Song': song_info['release'],\n",
        "            'Score': f\"{pred.est:.2f}\"\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Get recommendations for a sample user\n",
        "sample_user = df['user_id'].iloc[0]\n",
        "collab_recommendations = get_collaborative_recommendations(df, sample_user)\n",
        "print(f\"\\nRecommendations for user {sample_user}:\")\n",
        "display(collab_recommendations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJRAgUIUJgRD"
      },
      "source": [
        "## 3. Content-Based Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mWSvVHCJgRD"
      },
      "outputs": [],
      "source": [
        "def get_content_based_recommendations(df, song_id, n=5):\n",
        "    # Create song features\n",
        "    song_features = df.drop_duplicates('song_id').apply(\n",
        "        lambda x: f\"{x['artist_name']} {x['release']}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Calculate TF-IDF\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(song_features)\n",
        "\n",
        "    # Calculate similarity\n",
        "    idx = df[df['song_id'] == song_id].index[0]\n",
        "    sim_scores = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
        "\n",
        "    # Get similar song indices\n",
        "    similar_indices = sim_scores.argsort()[-n-1:-1][::-1]\n",
        "\n",
        "    return df.iloc[similar_indices][['artist_name', 'release']].drop_duplicates()\n",
        "\n",
        "# Get recommendations for a sample song\n",
        "sample_song = df['song_id'].iloc[0]\n",
        "song_info = df[df['song_id'] == sample_song].iloc[0]\n",
        "print(f\"\\nSimilar songs to {song_info['artist_name']} - {song_info['release']}:\")\n",
        "content_recommendations = get_content_based_recommendations(df, sample_song)\n",
        "display(content_recommendations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "music_recommender_colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}